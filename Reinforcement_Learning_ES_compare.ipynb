{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reinforcement_Learning_ES_compare",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ygGao1120/Reinforcement_Learning/blob/main/Reinforcement_Learning_ES_compare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9aY3EUEMSwc",
        "outputId": "4011710b-4b17-4ab9-ac11-12e56b4e35e7"
      },
      "source": [
        "\n",
        "%%bash\n",
        "\n",
        "# install required system dependencies\n",
        "apt-get install -y xvfb x11-utils\n",
        "\n",
        "# install required python dependencies (might need to install additional gym extras depending)\n",
        "pip install gym[box2d]==0.17.* pyvirtualdisplay==0.2.* PyOpenGL==3.1.* PyOpenGL-accelerate==3.1.*"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "x11-utils is already the newest version (7.7+3build1).\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.9).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Requirement already satisfied: gym[box2d]==0.17.* in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Collecting pyvirtualdisplay==0.2.*\n",
            "  Downloading PyVirtualDisplay-0.2.5-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: PyOpenGL==3.1.* in /usr/local/lib/python3.7/dist-packages (3.1.5)\n",
            "Collecting PyOpenGL-accelerate==3.1.*\n",
            "  Downloading PyOpenGL-accelerate-3.1.5.tar.gz (538 kB)\n",
            "Collecting EasyProcess\n",
            "  Downloading EasyProcess-0.3-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.19.5)\n",
            "Collecting box2d-py~=2.3.5\n",
            "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[box2d]==0.17.*) (0.16.0)\n",
            "Building wheels for collected packages: PyOpenGL-accelerate\n",
            "  Building wheel for PyOpenGL-accelerate (setup.py): started\n",
            "  Building wheel for PyOpenGL-accelerate (setup.py): finished with status 'done'\n",
            "  Created wheel for PyOpenGL-accelerate: filename=PyOpenGL_accelerate-3.1.5-cp37-cp37m-linux_x86_64.whl size=1599552 sha256=5bf3a1140a90e320b8a8583677a5169722267ffd41a555ebd7d8449abe573c45\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/f5/6f/169afb3f2d476c5e807f8515b3c9bc9b819c3962316aa804eb\n",
            "Successfully built PyOpenGL-accelerate\n",
            "Installing collected packages: EasyProcess, box2d-py, pyvirtualdisplay, PyOpenGL-accelerate\n",
            "Successfully installed EasyProcess-0.3 PyOpenGL-accelerate-3.1.5 box2d-py-2.3.8 pyvirtualdisplay-0.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FVyf9u5M212"
      },
      "source": [
        "import pyvirtualdisplay\n",
        "\n",
        "\n",
        "_display = pyvirtualdisplay.Display(visible=False,  # use False with Xvfb\n",
        "                                    size=(1400, 900))\n",
        "_ = _display.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cajTmtdyzoh"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "#import nevergrad as ng\n",
        "import cv2\n",
        "from scipy.optimize import minimize\n",
        "import scipy\n",
        "import scipy.stats as st\n",
        "from scipy.linalg import *\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_num_step = 1000"
      ],
      "metadata": {
        "id": "ArwUiGbcRHWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Solution:\n",
        "    def __init__(self, env: gym.Env, grad_method='FD', N=8, sigma=0.1,T = 200):\n",
        "        self.obs_dim = env.observation_space.shape\n",
        "        self.act_dim = env.action_space.n\n",
        "        print(self.obs_dim, self.act_dim)\n",
        "        self.params_shape = self.act_dim * self.obs_dim[0]\n",
        "        self.params_dot_shape = self.act_dim, self.obs_dim[0]\n",
        "        self.N = N\n",
        "        self.sigma = sigma\n",
        "        self.grad_method_name = grad_method\n",
        "        self.T = T\n",
        "        self.R = np.random.RandomState(seed = 40)\n",
        "        self.initial = self.R.rand(self.params_shape)\n",
        "\n",
        "    def fun(self, params: np.ndarray) -> float:\n",
        "        env = gym.make('CartPole-v1')\n",
        "        total_reward = 0.0\n",
        "        total_steps = 0\n",
        "        obs = env.reset()\n",
        "        params = params.reshape(self.params_dot_shape)\n",
        "        for t in range(max_num_step):\n",
        "\n",
        "            a = np.dot(params, obs)\n",
        "            a = np.argmax(a.flatten())\n",
        "            \n",
        "            obs, reward, done, _ = env.step(a)  # take a random action\n",
        "            total_reward += reward\n",
        "            total_steps += 1\n",
        "            if done:\n",
        "                break\n",
        "        # print(\"Episode done in %d steps, total reward %.2f\" % (total_steps, total_reward))\n",
        "        # print(total_reward)\n",
        "        return -total_reward\n",
        "\n",
        "    def gradient_term(self, params):\n",
        "        if self.grad_method_name == \"FD\":\n",
        "            return self.FD_grad(params)\n",
        "        elif self.grad_method_name == \"antithetic\":\n",
        "            return self.antithetic_grad(params)\n",
        "        elif self.grad_method_name == \"vanilla\":\n",
        "            return self.vanilla_grad(params)\n",
        "        elif self.grad_method_name == \"lasso\":\n",
        "            return self.lasso(self,params)\n",
        "        elif self.grad_method_name == \"ridge\":\n",
        "            return self.ridge(self,params)\n",
        "        elif self.grad_method_name == \"LP\":\n",
        "            return self.lp_gra(params)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown gradient method\")\n",
        "\n",
        "    def grad_estimate_method(self):\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def ridge(self,params):\n",
        "        F = self.fun(params)\n",
        "        y = np.zeros(self.N)\n",
        "        #generate noise with different methods\n",
        "        noise = self.independent_gau(self.N)\n",
        "        for i in range(self.N):\n",
        "            y[i] = self.fun(params+noise[i,:])-F\n",
        "\n",
        "        SSmodel=StandardScaler()\n",
        "        SSmodel.fit(noise)\n",
        "        Train_x=SSmodel.transform(noise)\n",
        "        model = Ridge(fit_intercept = False)\n",
        "        model.fit(Train_x,y)\n",
        "        return model.coef_/np.std(noise,axis = 0)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def lasso(self,params):\n",
        "        F = self.fun(params)\n",
        "        y = np.zeros(self.N)\n",
        "        #generate noise with different methods\n",
        "        noise = self.independent_gau(self.N)\n",
        "        for i in range(self.N):\n",
        "            y[i] = self.fun(params+noise[i,:])-F\n",
        "\n",
        "        SSmodel=StandardScaler()\n",
        "        SSmodel.fit(noise)\n",
        "        Train_x=SSmodel.transform(noise)\n",
        "        model = Lasso(fit_intercept = False)\n",
        "        model.fit(Train_x,y)\n",
        "        return model.coef_/np.std(noise,axis = 0)\n",
        "    \n",
        "    def lp_gra(self,params):\n",
        "        F = self.fun(params)\n",
        "        y = np.zeros(self.N)\n",
        "        #generate noise with different methods\n",
        "        noise = self.independent_gau(self.N)\n",
        "        for i in range(self.N):\n",
        "            y[i] = self.fun(params+noise[i,:])-F\n",
        "\n",
        "        def lp_decoding(z):\n",
        "            res=np.abs(y - np.dot(noise[i,:],z))\n",
        "            return np.sum(res)\n",
        "\n",
        "        curr_opt = scipy.optimize.minimize(lp_decoding,np.zeros(self.params_shape),tol = 0.01)\n",
        "        return curr_opt.x\n",
        "\n",
        "    # monte carlo based gradient\n",
        "    def vanilla_grad(self, params: np.ndarray) -> np.ndarray:\n",
        "        grad = np.zeros(params.shape)\n",
        "        # generate noise with different methods\n",
        "        #noise = self.independent_gau(self.N)\n",
        "        # noise = self.orth_gau()\n",
        "        noise = self.hadamard()\n",
        "        #noise = self.random_givens()\n",
        "\n",
        "        for i in range(self.N):\n",
        "            curr_noise = noise[i]\n",
        "            theta = params + self.sigma * curr_noise\n",
        "            F = self.fun(theta)\n",
        "            grad += F * curr_noise\n",
        "        grad = grad / (self.N * self.sigma)\n",
        "        return grad\n",
        "\n",
        "    def antithetic_grad(self, params: np.ndarray):\n",
        "        grad = np.zeros(params.shape)\n",
        "\n",
        "        # generate noise with different methods\n",
        "        #noise = self.independent_gau(self.N)\n",
        "        noise = self.orth_gau()\n",
        "        #noise = self.hadamard()\n",
        "        #noise = self.random_givens()\n",
        "\n",
        "        for i in range(self.N):\n",
        "            curr_noise = noise[i]\n",
        "            theta1 = params + self.sigma * curr_noise\n",
        "            theta2 = params - self.sigma * curr_noise\n",
        "            F1, F2 = self.fun(theta1), self.fun(theta2)\n",
        "            grad += (F1 - F2) * curr_noise\n",
        "        grad = grad / (2 * self.N * self.sigma)\n",
        "        return grad\n",
        "\n",
        "    def FD_grad(self, params: np.ndarray) -> np.ndarray:\n",
        "        grad = np.zeros(params.shape)\n",
        "        F = self.fun(params)\n",
        "\n",
        "        # generate noise with different methods\n",
        "        #noise = self.independent_gau(self.N)\n",
        "        #noise = self.orth_gau()\n",
        "        #noise = self.hadamard()\n",
        "        noise = self.random_givens()\n",
        "\n",
        "        for i in range(self.N):\n",
        "            curr_noise = noise[i, :]\n",
        "            theta = params + self.sigma * curr_noise\n",
        "            F1 = self.fun(theta)\n",
        "            grad += (F1 - F) * curr_noise\n",
        "        grad = grad / (self.N * self.sigma)\n",
        "        # print(grad.shape)\n",
        "        return grad\n",
        "\n",
        "    # monte carlo based gradient\n",
        "    def independent_gau(self,sigma=0.1):\n",
        "        res = np.empty((self.N, self.params_shape))\n",
        "        for i in range(self.N):\n",
        "            res[i] = np.random.multivariate_normal(mean=np.zeros(self.params_shape), cov=sigma * np.eye(self.params_shape))\n",
        "        return res\n",
        "    \n",
        "    def orth_gau(self,sigma = 0.1):\n",
        "        res = self.independent_gau()\n",
        "        ort = orth(res.T)\n",
        "        leng = np.linalg.norm(ort, axis=1, keepdims=True)\n",
        "        return ort/leng\n",
        "\n",
        "    \n",
        "    def hadamard(self):\n",
        "        T = self.T\n",
        "        n = self.params_shape\n",
        "        H1 = np.array([[1/np.sqrt(2),1/np.sqrt(2)],[1/np.sqrt(2),-1/np.sqrt(2)]])\n",
        "        H = H1\n",
        "        l = 2\n",
        "        while 2*l<=n:\n",
        "            H = np.kron(H,H1)\n",
        "            l*=2\n",
        "        n_h = H.shape[0]\n",
        "\n",
        "        M = np.eye(n_h)\n",
        "        for i in range(T):\n",
        "            vec=np.random.choice([-1,1],n_h)\n",
        "            D=np.diag(vec)\n",
        "            temp = np.dot(H,D)\n",
        "            M = np.dot(M,temp)\n",
        "        #leng = np.power(n,-(T-1)/2)\n",
        "        #leng = np.linalg.norm(M, axis=1, keepdims=True)\n",
        "        return M\n",
        "\n",
        "\n",
        "    def givens(self,n,i,j,theta):\n",
        "        G = np.eye(n)\n",
        "        G[i][i] = G[j][j] = np.cos(theta)\n",
        "        G[i][j] = -np.sin(theta)\n",
        "        G[j][i] = np.sin(theta)\n",
        "        return G\n",
        "\n",
        "    def random_givens(self):\n",
        "        T = self.T\n",
        "        n = self.params_shape\n",
        "        K = np.eye(n)\n",
        "        for t in range(T):\n",
        "            i = np.random.randint(0,n)\n",
        "            j = np.random.randint(0,n)\n",
        "            theta = 2*np.pi*np.random.rand()\n",
        "            K = np.dot(K,self.givens(n,i,j,theta))\n",
        "        return K\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    #optimization part\n",
        "    def optimize(self):\n",
        "        #initial = np.random.rand(self.params_shape)\n",
        "        print(self.initial)\n",
        "        opt = scipy.optimize.minimize(self.fun, self.initial, method='CG', jac=self.gradient_term,\n",
        "                                      options={'disp': True})\n",
        "        print(opt.x)\n",
        "        return opt.x,-opt.fun,opt.nit,opt.nfev,opt.njev"
      ],
      "metadata": {
        "id": "BaREpm1qfwvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    df = pd.DataFrame(columns = ['fun','nit','nfev','njev'])\n",
        "    for i in range(1000):\n",
        "        # optimization part, conjugate gradient method\n",
        "        sol = Solution(gym.make('CartPole-v1'),grad_method='vanilla')#change grad_method \n",
        "        params,fun_val,nit,nfev,njev = sol.optimize()\n",
        "        df = df.append({'fun':fun_val,'nit':nit,'nfev':nfev,'njev':njev},ignore_index = True)\n",
        "        params = params.reshape(sol.params_dot_shape)\n",
        "\n",
        "        env = gym.make('CartPole-v1')\n",
        "        obs = env.reset()\n",
        "        a_list = []\n",
        "        for t in range(max_num_step):\n",
        "            #env.render()\n",
        "            a = np.dot(params, obs)\n",
        "           \n",
        "            a = np.argmax(a.flatten())\n",
        "           \n",
        "            a_list.append(a)\n",
        "          \n",
        "            obs, reward, done, _ = env.step(a)  # take a random action\n",
        "            if done:\n",
        "                break\n",
        "        #print('a_list',a_list)"
      ],
      "metadata": {
        "id": "ibUr7JAJx6Ha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae8453c8-b4a0-4007-e1f5-434e65ec7a99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4,) 2\n",
            "[0.40768703 0.05536604 0.78853488 0.28730518 0.45035059 0.30391231\n",
            " 0.52639952 0.62381221]\n",
            "Warning: Desired error not necessarily achieved due to precision loss.\n",
            "         Current function value: -180.000000\n",
            "         Iterations: 1\n",
            "         Function evaluations: 26\n",
            "         Gradient evaluations: 16\n",
            "[0.66738736 0.28698635 0.67884208 0.28344279 0.29653929 0.48125098\n",
            " 0.74241221 0.68486573]\n"
          ]
        }
      ]
    }
  ]
}